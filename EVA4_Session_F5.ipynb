{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4 - Session 2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandeeppasala/EVA_S5/blob/master/EVA4_Session_F5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(20)\n",
        "        self.conv2 = nn.Conv2d(20, 16, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(16)\n",
        "        self.conv4 = nn.Conv2d(16, 10, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(10)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv5 = nn.Conv2d(10, 10, 3)\n",
        "        self.bn5 = nn.BatchNorm2d(10)\n",
        "        self.conv6 = nn.Conv2d(10, 20, 3)\n",
        "        self.bn6 = nn.BatchNorm2d(20)\n",
        "        self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.conv7 = nn.Conv2d(20, 10, 1)\n",
        "        self.dout = nn.Dropout(p=0.05)\n",
        "           \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(F.relu(self.conv1(x)))\n",
        "        x = self.dout(x)\n",
        "        x = self.pool1(self.bn2(F.relu(self.conv2(x))))\n",
        "        x = self.dout(x)\n",
        "        x = self.bn3(F.relu(self.conv3(x)))\n",
        "        x = self.dout(x)\n",
        "        x = self.pool2(self.bn4(F.relu(self.conv4(x))))\n",
        "        x = self.dout(x)\n",
        "        x = self.bn5(F.relu(self.conv5(x)))\n",
        "        x = self.dout(x)\n",
        "        x = self.bn6(F.relu(self.conv6(x)))\n",
        "        x = self.gap(x)\n",
        "        x = self.conv7(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xdydjYTZFyi3",
        "outputId": "dfaafbdc-ae31-4581-970e-d985c03612ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 20, 28, 28]             200\n",
            "       BatchNorm2d-2           [-1, 20, 28, 28]              40\n",
            "           Dropout-3           [-1, 20, 28, 28]               0\n",
            "            Conv2d-4           [-1, 16, 28, 28]           2,896\n",
            "       BatchNorm2d-5           [-1, 16, 28, 28]              32\n",
            "         MaxPool2d-6           [-1, 16, 14, 14]               0\n",
            "           Dropout-7           [-1, 16, 14, 14]               0\n",
            "            Conv2d-8           [-1, 16, 14, 14]           2,320\n",
            "       BatchNorm2d-9           [-1, 16, 14, 14]              32\n",
            "          Dropout-10           [-1, 16, 14, 14]               0\n",
            "           Conv2d-11           [-1, 10, 14, 14]           1,450\n",
            "      BatchNorm2d-12           [-1, 10, 14, 14]              20\n",
            "        MaxPool2d-13             [-1, 10, 7, 7]               0\n",
            "          Dropout-14             [-1, 10, 7, 7]               0\n",
            "           Conv2d-15             [-1, 10, 5, 5]             910\n",
            "      BatchNorm2d-16             [-1, 10, 5, 5]              20\n",
            "          Dropout-17             [-1, 10, 5, 5]               0\n",
            "           Conv2d-18             [-1, 20, 3, 3]           1,820\n",
            "      BatchNorm2d-19             [-1, 20, 3, 3]              40\n",
            "AdaptiveAvgPool2d-20             [-1, 20, 1, 1]               0\n",
            "           Conv2d-21             [-1, 10, 1, 1]             210\n",
            "================================================================\n",
            "Total params: 9,990\n",
            "Trainable params: 9,990\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.72\n",
            "Params size (MB): 0.04\n",
            "Estimated Total Size (MB): 0.76\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    \n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "    \n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "    print('Epoch:',epoch)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab_type": "code",
        "outputId": "23a54ad8-8f74-41e1-89e9-1737e0c8f400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = StepLR(optimizer, step_size=2, gamma=0.5)\n",
        "\n",
        "for epoch in range(1, 16):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    if (epoch > 5):\n",
        "      scheduler.step()\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09130630642175674 Batch_id=468 Accuracy=89.89: 100%|██████████| 469/469 [00:13<00:00, 35.74it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "\n",
            "Test set: Average loss: 0.0725, Accuracy: 9808/10000 (98.08%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0655662789940834 Batch_id=468 Accuracy=97.77: 100%|██████████| 469/469 [00:14<00:00, 33.35it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2\n",
            "\n",
            "Test set: Average loss: 0.0392, Accuracy: 9906/10000 (99.06%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.018748149275779724 Batch_id=468 Accuracy=98.13: 100%|██████████| 469/469 [00:13<00:00, 35.81it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3\n",
            "\n",
            "Test set: Average loss: 0.0355, Accuracy: 9902/10000 (99.02%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.011912320740520954 Batch_id=468 Accuracy=98.48: 100%|██████████| 469/469 [00:13<00:00, 34.63it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4\n",
            "\n",
            "Test set: Average loss: 0.0265, Accuracy: 9925/10000 (99.25%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.01389436423778534 Batch_id=468 Accuracy=98.60: 100%|██████████| 469/469 [00:13<00:00, 35.39it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5\n",
            "\n",
            "Test set: Average loss: 0.0261, Accuracy: 9922/10000 (99.22%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.017089465633034706 Batch_id=468 Accuracy=98.71: 100%|██████████| 469/469 [00:13<00:00, 33.97it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6\n",
            "\n",
            "Test set: Average loss: 0.0263, Accuracy: 9927/10000 (99.27%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.025883018970489502 Batch_id=468 Accuracy=98.74: 100%|██████████| 469/469 [00:13<00:00, 35.11it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7\n",
            "\n",
            "Test set: Average loss: 0.0237, Accuracy: 9928/10000 (99.28%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.015937289223074913 Batch_id=468 Accuracy=98.94: 100%|██████████| 469/469 [00:13<00:00, 34.18it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8\n",
            "\n",
            "Test set: Average loss: 0.0195, Accuracy: 9935/10000 (99.35%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.034143008291721344 Batch_id=468 Accuracy=99.02: 100%|██████████| 469/469 [00:13<00:00, 37.30it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9\n",
            "\n",
            "Test set: Average loss: 0.0193, Accuracy: 9938/10000 (99.38%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.005144586320966482 Batch_id=468 Accuracy=99.14: 100%|██████████| 469/469 [00:14<00:00, 32.85it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10\n",
            "\n",
            "Test set: Average loss: 0.0196, Accuracy: 9940/10000 (99.40%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.014271460473537445 Batch_id=468 Accuracy=99.06: 100%|██████████| 469/469 [00:13<00:00, 35.78it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11\n",
            "\n",
            "Test set: Average loss: 0.0189, Accuracy: 9945/10000 (99.45%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.02465302310883999 Batch_id=468 Accuracy=99.19: 100%|██████████| 469/469 [00:13<00:00, 34.29it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12\n",
            "\n",
            "Test set: Average loss: 0.0187, Accuracy: 9941/10000 (99.41%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.1018444299697876 Batch_id=468 Accuracy=99.17: 100%|██████████| 469/469 [00:13<00:00, 34.85it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13\n",
            "\n",
            "Test set: Average loss: 0.0182, Accuracy: 9946/10000 (99.46%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06586676836013794 Batch_id=468 Accuracy=99.12: 100%|██████████| 469/469 [00:14<00:00, 33.18it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14\n",
            "\n",
            "Test set: Average loss: 0.0185, Accuracy: 9941/10000 (99.41%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0033226311206817627 Batch_id=468 Accuracy=99.13: 100%|██████████| 469/469 [00:13<00:00, 35.79it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15\n",
            "\n",
            "Test set: Average loss: 0.0178, Accuracy: 9944/10000 (99.44%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLz8QpyiTEZS",
        "colab_type": "text"
      },
      "source": [
        "Target:\n",
        "\n",
        "As the parameters are reduced batch normalization, dropout, GAP are aaded to the model along with slight rotation transform.\n",
        "\n",
        "Its time use the learning rate and improve the accuracy.\n",
        "\n",
        "Results:\n",
        "\n",
        "Parameters: >10K\n",
        "\n",
        "Best Training Accuracy: 99.19%\n",
        "\n",
        "Best Test Accuracy: 99.46% (Seen Consistently in the last 6 epochs)\n",
        "\n",
        "Analysis:\n",
        "\n",
        "Model is light weight as params are reduced\n",
        "\n",
        "This is a fit model. \n",
        "\n",
        "Model can be further improved.\n",
        "\n",
        "\n"
      ]
    }
  ]
}